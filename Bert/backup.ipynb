{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert 소개\n",
    "\n",
    "* Transformer의 encoder 부분만 활용\n",
    "* NLP 분야에 Fine-Tuning 개념 도입\n",
    "* Masked Language Model[MLM] 뿐만아니라 Next Sentence Prediction[NSP]를 통해 학습\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Next Sentence Prediction** 이해하기\n",
    "\n",
    "* 이전 문장이 현재 문장과 연속적인 내용인지를 판단하는 binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt,Hannanum\n",
    "import pandas as pd\n",
    "\n",
    "books = pd.read_csv('./data/bookinfo.csv', index_col=0)\n",
    "\n",
    "book_list = books.iloc[:1000,2:]\n",
    "\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(ist:list) -> str :\n",
    "    type_to_str = list(map(str,ist))\n",
    "    word = ''.join(type_to_str)\n",
    "    return word\n",
    "\n",
    "word_list = [list_to_string(ist[1].tolist()) for ist in book_list.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "java.lang.ArrayIndexOutOfBoundsException: Index 10000 out of bounds for length 10000\n",
      "\tat kr.ac.kaist.swrc.jhannanum.plugin.MajorPlugin.PosTagger.HmmPosTagger.HMMTagger.new_mnode(HMMTagger.java:354)\n",
      "\tat kr.ac.kaist.swrc.jhannanum.plugin.MajorPlugin.PosTagger.HmmPosTagger.HMMTagger.tagPOS(HMMTagger.java:143)\n",
      "\tat kr.ac.kaist.swrc.jhannanum.hannanum.Workflow.analyzeInSingleThread(Workflow.java:857)\n",
      "\tat kr.ac.kaist.swrc.jhannanum.hannanum.Workflow.analyze(Workflow.java:521)\n",
      "\tat kr.lucypark.jhannanum.comm.HannanumInterface.simplePos09(Unknown Source)\n",
      "java.lang.ArrayIndexOutOfBoundsException\n",
      "java.lang.ArrayIndexOutOfBoundsException\n",
      "java.lang.ArrayIndexOutOfBoundsException\n"
     ]
    }
   ],
   "source": [
    "han = Hannanum()\n",
    "corpus = [han.morphs(word) for word in word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame(corpus)\n",
    "1000-sum(a.iloc[:,3000].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/yangwoolee/git_repo/Deep_learning_from_scratch/Bert/Training_Transformer_From_Scratch.ipynb 셀 6\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Deep_learning_from_scratch/Bert/Training_Transformer_From_Scratch.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Deep_learning_from_scratch/Bert/Training_Transformer_From_Scratch.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m tensor_corpus \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(pd\u001b[39m.\u001b[39;49mDataFrame(corpus))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Deep_learning_from_scratch/Bert/Training_Transformer_From_Scratch.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m tensor_corpus[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor_corpus = torch.tensor(pd.DataFrame(corpus))\n",
    "\n",
    "tensor_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45756"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextEncoding() :\n",
    "    def __init__(self, word_corpus) :\n",
    "        self.pad_token = \"[PAD]\"\n",
    "        self.unk_token = \"[UNK]\"\n",
    "\n",
    "        token_to_id = {}\n",
    "        id_to_token = {}\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2097164ba635ebffc0e3795dc845ae25b57eedf0c1eb5773ded6aee9fc1b279"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
